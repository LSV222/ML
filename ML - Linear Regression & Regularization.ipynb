{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5af925",
   "metadata": {},
   "source": [
    "## Linear regression \n",
    "\n",
    "y= ax + b\n",
    "\n",
    "La idea es generar una linea que minimice los errores a dicha linea.\n",
    "OBS: LinearRegression de sklearn hace MCO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357e92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train,  Xtest, y_train ,y_test = train_test_split ( X ,y ,test_size=0.3 ,random_state=42)\n",
    "reg_all= LinearRegression()\n",
    "reg_all.fit(X_train, y_train)\n",
    "y_pred= reg_all.predict(X_test)\n",
    "\n",
    "#calcular Rcuadrado\n",
    "Regl_all.score(x_test, y_tes) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879e049",
   "metadata": {},
   "source": [
    "R cuadrado  =  % de varianza de las observaciones explicadas por la regresion\n",
    "Error cuadratico medio = ECM = MSE = es el promedio de elevar al cuadrado los errores de cada observacion y prediccion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b52e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred, squared=False) #Squared=False devuelve la raiz de ECM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c966468f",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Minimizabamos en la regresion lineal, la funcion de errores cuadrados, de tal manera para elegir a y b.\n",
    "La realidad es que de la regresion lineal puede resultarnos en coeficientes muy grandes; que a su vez nos pueden conducir  \n",
    "en overfitting ( que el modelo solo explique los datos de entrenamiento y prueba).  \n",
    "Para evitarlo , es comun agregar a la \"funcion de perdida\" con la que elegimos a y b, una penalizacion a coeficientes muy grandes => Esto es la regularizacion\n",
    "\n",
    "RIDGE \n",
    "\n",
    "-Funcion de perdida = MCO +  alpha. sum[(a sub i )^2]\n",
    "-Alpha es una eleccion de hyperparametro que tenemos que hacer (similar a k en KNN)\n",
    "-Alpha controla la complejidad del modelo: siendo alpha=0 es MCO ; siendo alpha muy grande puede conducir a underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f102ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "scores = []\n",
    "for alpha in [0.1 , 1 , 10 , 100 , 1000]:\n",
    "    ridge= Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train , y_train)\n",
    "    y_pred= ridge.pred(X_test)\n",
    "    scores.append(ridge.score(X_test,y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae91d0",
   "metadata": {},
   "source": [
    "LASSO\n",
    "Lasso es otra regularizacion, pero en este caso con  alpha*sum( abs(a sub i) )   \n",
    "El codigo para usar Lasso es analogo al de Ridge.\n",
    "Adem√°s Lasso, puede ser usado para sellecionar variables importantes de un dataset.\n",
    "Achica los coeficientes de las variables menos importantes a cero\n",
    "Las variables de las cuales no lleva a 0 sus coeficientes son las elegidas por Lasso. Esto es util para la comunicacion a audiencias no tecnicas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba403dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "X= df.drop(\"y-column\", axis=1).values\n",
    "y= df[\"y-columns\"].values\n",
    "names = df.drop(\"y-column\", axis=1).columns\n",
    "lasso= Lasso (alpha=0.1)\n",
    "lasso_coef = lasso.fit(X,y).coef_  # COMO SOLO QUEREMOS SACAR LA IMPORTANCIA DE LAS VARIABLES, NO DIVIDIMOS EL DATASET\n",
    "\n",
    "plt.bar(names, lasso_coef )\n",
    "plt.xticks (rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
