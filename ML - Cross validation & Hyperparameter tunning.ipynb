{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7662bbcd",
   "metadata": {},
   "source": [
    "## Cross validation & Hyperparameter tuning\n",
    "\n",
    "Cross validation es probar un modelo ( o distintos modelos) , dividiendo al data en test y training; pero iterando la medicion de resultados de manera tal que cada parte de la data haya sido utilizada en test ; y luego resumimos (agregamos) los resultados como resultados globales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa07f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score , KFold\n",
    "kf= KFold (n_splits=6 ,shuffle= True ,random_state=42 ) \n",
    "reg= LinearRegression()\n",
    "cv_results = cross_val_score(reg, X, y ,cv=kf )\n",
    "print(cv_results)\n",
    "print(np.mean(cv_results)) ##aca se calcula la media de los resultados, me parece interesante tambien analizar el minimo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa3987",
   "metadata": {},
   "source": [
    "Estos \"modelos\" distintos que podemos probar y medir su utilidad con cross validation ; incluyen distintas versiones de un mismo tipo de modelo (con mismo algoritmo ) pero cambiando hyperparametros como tipo de distancia o cantidad de vecinos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "kf = KFold(n_splits =5 , shuffle =True , random_state=42 )\n",
    "param_grid = {\"alpha\": np.arange(0.0001 , 1, 10) , \"solver\": [\"sag\", \"lsqr\"]}\n",
    "ridge= Ridge()\n",
    "ridge_cv = GridSearchCV(ridge ,param_grid ,cv=kf)\n",
    "ridge_cv.fit(X_train,y_train)\n",
    "print(ridge_cv.best_params_ , ridge_cv.best_score_)  # para cada modelo del grid devuelve el mejor alpha , y el promedio de\n",
    "                                                     # score de los folds de ese parametro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d79c02",
   "metadata": {},
   "source": [
    "LIMITANTES DE GRIDSEARCH\n",
    ".Poca escalabilidad. La cantidad de fit's de modelos que usa es nro_folds*nro_hyperparametros*nro_valores_hyperparametros\n",
    " EJ : con 10 folds, 3 hyperparametros y 30 valores necesita 900! fits\n",
    " \n",
    "De todas maneras, tenemos la alternativa de RandomizedSearchCV\n",
    "Es muy similar a la anterior, con la diferencia de que elige aleatoriamente valores para los hyperparametros, en vez de buscar exhaustivamente entre todas las opciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "kf = KFold(n_splits =5 , shuffle =True , random_state=42 )\n",
    "param_grid = {\"alpha\": np.arrange(0.0001 , 1, 10) , \"solver\": [\"sag\", \"lsqr\"]}\n",
    "ridge= Ridge()\n",
    "ridge_cv = RandomizedSearchCV(ridge ,param_grid ,cv=kf , n_iter=2)  ##con n_iter=2 pasamos de 50 fit a 10  (splits*nro_a)\n",
    "ridge_cv.fit(X_train,y_train)\n",
    "print(ridge_cv.best_params_ , ridge_cv.best_score_) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
